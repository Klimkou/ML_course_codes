{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4a2b647-6480-4c0c-b36f-26e0bf7c6bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/num_epochs: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 325.89it/s, Loss=0.181]\n",
      "Epoch 2/num_epochs: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 318.26it/s, Loss=0.17]\n",
      "Epoch 3/num_epochs: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 325.19it/s, Loss=0.14]\n",
      "Epoch 4/num_epochs: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 324.45it/s, Loss=0.203]\n",
      "Epoch 5/num_epochs: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 314.48it/s, Loss=0.0818]\n",
      "Epoch 6/num_epochs: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 301.00it/s, Loss=0.0656]\n",
      "Epoch 7/num_epochs: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 296.10it/s, Loss=0.0602]\n",
      "Epoch 8/num_epochs: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 295.43it/s, Loss=0.0991]\n",
      "Epoch 9/num_epochs: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 268.90it/s, Loss=0.116]\n",
      "Epoch 10/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 353.05it/s, Loss=0.0748]\n",
      "Epoch 11/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 350.51it/s, Loss=0.0449]\n",
      "Epoch 12/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 336.62it/s, Loss=0.0298]\n",
      "Epoch 13/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 335.82it/s, Loss=0.0208]\n",
      "Epoch 14/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 348.40it/s, Loss=0.0718]\n",
      "Epoch 15/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 327.45it/s, Loss=0.0426]\n",
      "Epoch 16/num_epochs: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 332.67it/s, Loss=0.00389]\n",
      "Epoch 17/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 338.87it/s, Loss=0.0125]\n",
      "Epoch 18/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 336.66it/s, Loss=0.0347]\n",
      "Epoch 19/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 341.75it/s, Loss=0.0167]\n",
      "Epoch 20/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 326.37it/s, Loss=0.0322]\n",
      "Epoch 21/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 327.61it/s, Loss=0.0625]\n",
      "Epoch 22/num_epochs: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 338.56it/s, Loss=0.011]\n",
      "Epoch 23/num_epochs: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 326.95it/s, Loss=0.161]\n",
      "Epoch 24/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 333.75it/s, Loss=0.0161]\n",
      "Epoch 25/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 316.22it/s, Loss=0.0013]\n",
      "Epoch 26/num_epochs: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 334.73it/s, Loss=0.106]\n",
      "Epoch 27/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 331.45it/s, Loss=0.0202]\n",
      "Epoch 28/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 346.78it/s, Loss=0.0019]\n",
      "Epoch 29/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 330.00it/s, Loss=0.0256]\n",
      "Epoch 30/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 320.43it/s, Loss=0.0237]\n",
      "Epoch 31/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 334.55it/s, Loss=0.0451]\n",
      "Epoch 32/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 327.56it/s, Loss=0.0397]\n",
      "Epoch 33/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 328.14it/s, Loss=0.0405]\n",
      "Epoch 34/num_epochs: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 325.92it/s, Loss=0.00254]\n",
      "Epoch 35/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 325.71it/s, Loss=0.0127]\n",
      "Epoch 36/num_epochs: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 322.12it/s, Loss=0.107]\n",
      "Epoch 37/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 328.98it/s, Loss=0.0124]\n",
      "Epoch 38/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 339.28it/s, Loss=0.0615]\n",
      "Epoch 39/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 336.10it/s, Loss=0.0156]\n",
      "Epoch 40/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 350.77it/s, Loss=0.0814]\n",
      "Epoch 41/num_epochs: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 362.46it/s, Loss=0.032]\n",
      "Epoch 42/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 349.51it/s, Loss=0.0277]\n",
      "Epoch 43/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 352.12it/s, Loss=0.0815]\n",
      "Epoch 44/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 329.83it/s, Loss=0.0739]\n",
      "Epoch 45/num_epochs: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 347.00it/s, Loss=0.00395]\n",
      "Epoch 46/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 349.19it/s, Loss=0.0171]\n",
      "Epoch 47/num_epochs: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 360.04it/s, Loss=0.00813]\n",
      "Epoch 48/num_epochs: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 357.90it/s, Loss=0.005]\n",
      "Epoch 49/num_epochs: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 322.91it/s, Loss=0.00132]\n",
      "Epoch 50/num_epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 341.53it/s, Loss=0.0047]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Custom Dataset class\n",
    "class MNISTSequenceDataset(Dataset):\n",
    "    def __init__(self, data, labels, mean=0.1307, std=0.3081):\n",
    "        # First normalize to [0,1] by dividing by 255\n",
    "        normalized_data = data.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Then apply mean/std normalization\n",
    "        normalized_data = (normalized_data - mean) / std\n",
    "        \n",
    "        self.data = torch.FloatTensor(normalized_data)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# MLP Model\n",
    "class MNISTMLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_size=[100,50], num_classes=10):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(hidden_size[0], hidden_size[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(hidden_size[1], num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        return self.model(x)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/num_epochs\")\n",
    "        for images, labels in progress_bar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Reshape images to sequence format (batch_size, sequence_length, input_size)\n",
    "            images = images.view(-1, 784, 1)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "            \"Loss\": loss.item(),\n",
    "        })\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_correct / train_total)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                images = images.view(-1, 784, 1)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            val_losses.append(val_loss)\n",
    "            val_accs.append(val_correct / val_total)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv('./data/mnist/train.csv')\n",
    "labels = df['label'].values\n",
    "pixels = df.drop('label', axis=1).values\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(pixels, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = MNISTSequenceDataset(X_train, y_train)\n",
    "val_dataset = MNISTSequenceDataset(X_val, y_val)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "# Initialize model\n",
    "model = MNISTMLPClassifier().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 50\n",
    "train_losses, val_losses, train_accs, val_accs = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8c6e22-2c88-4b62-a092-93dea032dad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
